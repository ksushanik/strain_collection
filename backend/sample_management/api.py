"""
API endpoints –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–±—Ä–∞–∑—Ü–∞–º–∏
"""

from rest_framework.decorators import api_view
from rest_framework.response import Response
from rest_framework import status
from django.db import transaction, connection, IntegrityError
from django.db.models import Q, Prefetch, Count
from django.views.decorators.csrf import csrf_exempt
from django.core.exceptions import ValidationError as DjangoValidationError
from pydantic import BaseModel, Field, ValidationError, field_validator
from typing import Optional, List, Dict, Iterable
from datetime import datetime, timedelta
import logging
from drf_spectacular.utils import extend_schema, OpenApiParameter, OpenApiResponse
from drf_spectacular.openapi import AutoSchema
from django.http import HttpResponse
from django.utils import timezone

from .models import Sample, SampleGrowthMedia, SamplePhoto, SampleCharacteristic, SampleCharacteristicValue
from reference_data.models import IndexLetter, IUKColor, AmylaseVariant, GrowthMedium, Source, Location
from strain_management.models import Strain
from storage_management.models import Storage
from collection_manager.schemas import SampleCharacteristicSchema, SampleCharacteristicValueSchema
from collection_manager.utils import log_change, generate_batch_id, model_to_dict

logger = logging.getLogger(__name__)


BOOLEAN_CHARACTERISTIC_FIELDS: Dict[str, Iterable[str]] = {
    'mobilizes_phosphates': ('mobilizes_phosphates', '–ú–æ–±–∏–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–æ—Å—Ñ–∞—Ç—ã'),
    'stains_medium': ('stains_medium', '–û–∫—Ä–∞—à–∏–≤–∞–µ—Ç —Å—Ä–µ–¥—É'),
    'produces_siderophores': ('produces_siderophores', '–í—ã—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–∏–¥–µ—Ä–æ—Ñ–æ—Ä—ã'),
    'is_identified': ('is_identified', '–ò–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω'),
    'has_genome': ('has_genome', '–ï—Å—Ç—å –≥–µ–Ω–æ–º'),
    'has_biochemistry': ('has_biochemistry', '–ï—Å—Ç—å –±–∏–æ—Ö–∏–º–∏—è'),
    'seq_status': ('seq_status', '–°–µ–∫–≤–µ–Ω–∏—Ä–æ–≤–∞–Ω'),
}


def _coerce_to_bool(value) -> Optional[bool]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∫ –±—É–ª–µ–≤–æ–º—É —Ç–∏–ø—É, –≤–æ–∑–≤—Ä–∞—â–∞—è None –ø—Ä–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏."""

    if value is None:
        return None
    if isinstance(value, bool):
        return value
    if isinstance(value, (int, float)):
        return bool(value)
    if isinstance(value, str):
        normalized = value.strip().lower()
        if normalized in {'true', '1', 'yes', 'y', 'on'}:
            return True
        if normalized in {'false', '0', 'no', 'n', 'off'}:
            return False
    return None


def _parse_ids(raw_ids) -> List[int]:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≤—Ö–æ–¥–Ω–æ–π —Å–ø–∏—Å–æ–∫/—Å—Ç—Ä–æ–∫—É ID –≤ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª."""

    if raw_ids is None:
        return []

    candidates: List[int] = []

    if isinstance(raw_ids, list):
        sources = raw_ids
    else:
        sources = str(raw_ids).replace(',', ' ').split()

    for token in sources:
        try:
            value = int(token)
        except (TypeError, ValueError):
            continue
        if value > 0:
            candidates.append(value)

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º dict.fromkeys –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞ –∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    return list(dict.fromkeys(candidates))


def reset_sequence(model_class):
    """–°–±—Ä–æ—Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–≤—Ç–æ–∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞ –¥–ª—è –º–æ–¥–µ–ª–∏"""
    table_name = model_class._meta.db_table
    with connection.cursor() as cursor:
        cursor.execute(f"SELECT setval(pg_get_serial_sequence('{table_name}', 'id'), COALESCE(MAX(id), 1)) FROM {table_name};")


class SampleSchema(BaseModel):
    """–°—Ö–µ–º–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–∑—Ü–æ–≤"""

    id: Optional[int] = Field(None, ge=1, description="ID –æ–±—Ä–∞–∑—Ü–∞")
    index_letter_id: Optional[int] = Field(None, ge=1, description="ID –∏–Ω–¥–µ–∫—Å–Ω–æ–π –±—É–∫–≤—ã")
    strain_id: Optional[int] = Field(None, ge=1, description="ID —à—Ç–∞–º–º–∞")
    storage_id: Optional[int] = Field(None, ge=1, description="ID —Ö—Ä–∞–Ω–∏–ª–∏—â–∞")
    original_sample_number: Optional[str] = Field(None, max_length=100, description="–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä –æ–±—Ä–∞–∑—Ü–∞")
    source_id: Optional[int] = Field(None, ge=1, description="ID –∏—Å—Ç–æ—á–Ω–∏–∫–∞")
    location_id: Optional[int] = Field(None, ge=1, description="ID –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è")
    appendix_note: Optional[str] = Field(None, max_length=1000, description="–¢–µ–∫—Å—Ç –ø—Ä–∏–º–µ—á–∞–Ω–∏—è")
    comment: Optional[str] = Field(None, max_length=1000, description="–¢–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è")
    has_photo: bool = Field(default=False, description="–ï—Å—Ç—å –ª–∏ —Ñ–æ—Ç–æ")
    iuk_color_id: Optional[int] = Field(None, ge=1, description="ID —Ü–≤–µ—Ç–∞ –ò–£–ö")
    amylase_variant_id: Optional[int] = Field(None, ge=1, description="ID –≤–∞—Ä–∏–∞–Ω—Ç–∞ –∞–º–∏–ª–∞–∑—ã")
    growth_media_ids: Optional[List[int]] = Field(None, description="–°–ø–∏—Å–æ–∫ ID —Å—Ä–µ–¥ —Ä–æ—Å—Ç–∞")
    characteristics: Optional[dict] = Field(None, description="–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –æ–±—Ä–∞–∑—Ü–∞")
    created_at: Optional[datetime] = Field(None, description="–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è")
    updated_at: Optional[datetime] = Field(None, description="–î–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è")

    @field_validator("original_sample_number", "appendix_note", "comment")
    @classmethod
    def validate_text_fields(cls, v: Optional[str]) -> Optional[str]:
        if v is not None:
            v = v.strip()
            return v if v else None
        return v

    @field_validator("growth_media_ids")
    @classmethod
    def validate_growth_media_ids(cls, v: Optional[List[int]]) -> Optional[List[int]]:
        if v is not None:
            v = list(set(filter(None, v)))
            return v if v else None
        return v

    class Config:
        from_attributes = True


class CreateSampleSchema(BaseModel):
    """–°—Ö–µ–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—Ä–∞–∑—Ü–∞ –±–µ–∑ ID"""
    
    index_letter_id: Optional[int] = Field(None, ge=1, description="ID –∏–Ω–¥–µ–∫—Å–Ω–æ–π –±—É–∫–≤—ã")
    strain_id: Optional[int] = Field(None, ge=1, description="ID —à—Ç–∞–º–º–∞")
    storage_id: Optional[int] = Field(None, ge=1, description="ID —Ö—Ä–∞–Ω–∏–ª–∏—â–∞")
    original_sample_number: Optional[str] = Field(None, max_length=100, description="–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä –æ–±—Ä–∞–∑—Ü–∞")
    source_id: Optional[int] = Field(None, ge=1, description="ID –∏—Å—Ç–æ—á–Ω–∏–∫–∞")
    location_id: Optional[int] = Field(None, ge=1, description="ID –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è")
    appendix_note: Optional[str] = Field(None, max_length=1000, description="–¢–µ–∫—Å—Ç –ø—Ä–∏–º–µ—á–∞–Ω–∏—è")
    comment: Optional[str] = Field(None, max_length=1000, description="–¢–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è")
    has_photo: bool = Field(default=False, description="–ï—Å—Ç—å –ª–∏ —Ñ–æ—Ç–æ")
    iuk_color_id: Optional[int] = Field(None, ge=1, description="ID —Ü–≤–µ—Ç–∞ –ò–£–ö")
    amylase_variant_id: Optional[int] = Field(None, ge=1, description="ID –≤–∞—Ä–∏–∞–Ω—Ç–∞ –∞–º–∏–ª–∞–∑—ã")
    growth_media_ids: Optional[List[int]] = Field(None, description="–°–ø–∏—Å–æ–∫ ID —Å—Ä–µ–¥ —Ä–æ—Å—Ç–∞")
    characteristics: Optional[dict] = Field(None, description="–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –æ–±—Ä–∞–∑—Ü–∞")
    
    @field_validator("original_sample_number", "appendix_note", "comment")
    @classmethod
    def validate_text_fields(cls, v: Optional[str]) -> Optional[str]:
        if v is not None:
            v = v.strip()
            return v if v else None
        return v

    @field_validator("growth_media_ids")
    @classmethod
    def validate_growth_media_ids(cls, v: Optional[List[int]]) -> Optional[List[int]]:
        if v is not None:
            v = list(set(filter(None, v)))
            return v if v else None
        return v


class UpdateSampleSchema(BaseModel):
    """–°—Ö–µ–º–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –æ–±—Ä–∞–∑—Ü–∞ –±–µ–∑ –ø–æ–ª—è has_photo (—É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)"""
    
    index_letter_id: Optional[int] = Field(None, ge=1, description="ID –∏–Ω–¥–µ–∫—Å–Ω–æ–π –±—É–∫–≤—ã")
    strain_id: Optional[int] = Field(None, ge=1, description="ID —à—Ç–∞–º–º–∞")
    storage_id: Optional[int] = Field(None, ge=1, description="ID —Ö—Ä–∞–Ω–∏–ª–∏—â–∞")
    original_sample_number: Optional[str] = Field(None, max_length=100, description="–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä –æ–±—Ä–∞–∑—Ü–∞")
    source_id: Optional[int] = Field(None, ge=1, description="ID –∏—Å—Ç–æ—á–Ω–∏–∫–∞")
    location_id: Optional[int] = Field(None, ge=1, description="ID –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è")
    appendix_note: Optional[str] = Field(None, max_length=1000, description="–¢–µ–∫—Å—Ç –ø—Ä–∏–º–µ—á–∞–Ω–∏—è")
    comment: Optional[str] = Field(None, max_length=1000, description="–¢–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è")
    # has_photo –∏—Å–∫–ª—é—á–µ–Ω–æ - —É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ —Å–∏–≥–Ω–∞–ª—ã –ø—Ä–∏ –æ–ø–µ—Ä–∞—Ü–∏—è—Ö —Å —Ñ–æ—Ç–æ
    iuk_color_id: Optional[int] = Field(None, ge=1, description="ID —Ü–≤–µ—Ç–∞ –ò–£–ö")
    amylase_variant_id: Optional[int] = Field(None, ge=1, description="ID –≤–∞—Ä–∏–∞–Ω—Ç–∞ –∞–º–∏–ª–∞–∑—ã")
    growth_media_ids: Optional[List[int]] = Field(None, description="–°–ø–∏—Å–æ–∫ ID —Å—Ä–µ–¥ —Ä–æ—Å—Ç–∞")
    characteristics: Optional[dict] = Field(None, description="–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –æ–±—Ä–∞–∑—Ü–∞")
    
    @field_validator("original_sample_number", "appendix_note", "comment")
    @classmethod
    def validate_text_fields(cls, v: Optional[str]) -> Optional[str]:
        if v is not None:
            v = v.strip()
            return v if v else None
        return v

    @field_validator("growth_media_ids")
    @classmethod
    def validate_growth_media_ids(cls, v: Optional[List[int]]) -> Optional[List[int]]:
        if v is not None:
            v = list(set(filter(None, v)))
            return v if v else None
        return v


@extend_schema(
    methods=['GET'],
    operation_id="samples_list",
    summary="–°–ø–∏—Å–æ–∫ –æ–±—Ä–∞–∑—Ü–æ–≤",
    description="–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –æ–±—Ä–∞–∑—Ü–æ–≤ —Å –ø–æ–∏—Å–∫–æ–º –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π",
    parameters=[
        OpenApiParameter(name='search', type=str, description='–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å'),
        OpenApiParameter(name='strain_id', type=int, description='ID —à—Ç–∞–º–º–∞'),
        OpenApiParameter(name='storage_id', type=int, description='ID —Ö—Ä–∞–Ω–∏–ª–∏—â–∞'),
        OpenApiParameter(name='page', type=int, description='–ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã'),
        OpenApiParameter(name='limit', type=int, description='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ'),
    ],
    responses={
        200: OpenApiResponse(description="–°–ø–∏—Å–æ–∫ –æ–±—Ä–∞–∑—Ü–æ–≤"),
        500: OpenApiResponse(description="–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"),
    }
)
@extend_schema(
    methods=['POST'],
    operation_id="samples_create",
    summary="–°–æ–∑–¥–∞–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–∞",
    description="–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞",
    responses={
        201: OpenApiResponse(description="–û–±—Ä–∞–∑–µ—Ü —Å–æ–∑–¥–∞–Ω"),
        400: OpenApiResponse(description="–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"),
        500: OpenApiResponse(description="–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"),
    }
)
@api_view(['GET', 'POST'])
def list_samples(request):
    """–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –æ–±—Ä–∞–∑—Ü–æ–≤ —Å –ø–æ–∏—Å–∫–æ–º –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π (GET) –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞ (POST)"""
    if request.method == 'POST':
        # POST request - —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞
        try:
            validated_data = CreateSampleSchema.model_validate(request.data)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
            if validated_data.index_letter_id and not IndexLetter.objects.filter(id=validated_data.index_letter_id).exists():
                return Response({'error': f'–ò–Ω–¥–µ–∫—Å–Ω–∞—è –±—É–∫–≤–∞ —Å ID {validated_data.index_letter_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}, 
                              status=status.HTTP_400_BAD_REQUEST)
            
            if validated_data.strain_id and not Strain.objects.filter(id=validated_data.strain_id).exists():
                return Response({'error': f'–®—Ç–∞–º–º —Å ID {validated_data.strain_id} –Ω–µ –Ω–∞–π–¥–µ–Ω'}, 
                              status=status.HTTP_400_BAD_REQUEST)
            
            if validated_data.storage_id and not Storage.objects.filter(id=validated_data.storage_id).exists():
                return Response({'error': f'–•—Ä–∞–Ω–∏–ª–∏—â–µ —Å ID {validated_data.storage_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}, 
                              status=status.HTTP_400_BAD_REQUEST)
            
            if validated_data.source_id and not Source.objects.filter(id=validated_data.source_id).exists():
                return Response({'error': f'–ò—Å—Ç–æ—á–Ω–∏–∫ —Å ID {validated_data.source_id} –Ω–µ –Ω–∞–π–¥–µ–Ω'}, 
                              status=status.HTTP_400_BAD_REQUEST)
            
            if validated_data.location_id and not Location.objects.filter(id=validated_data.location_id).exists():
                return Response({'error': f'–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ —Å ID {validated_data.location_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}, 
                              status=status.HTTP_400_BAD_REQUEST)
            
            if validated_data.iuk_color_id and not IUKColor.objects.filter(id=validated_data.iuk_color_id).exists():
                return Response({'error': f'–¶–≤–µ—Ç –ò–£–ö —Å ID {validated_data.iuk_color_id} –Ω–µ –Ω–∞–π–¥–µ–Ω'}, 
                              status=status.HTTP_400_BAD_REQUEST)
            
            if validated_data.amylase_variant_id and not AmylaseVariant.objects.filter(id=validated_data.amylase_variant_id).exists():
                return Response({'error': f'–í–∞—Ä–∏–∞–Ω—Ç –∞–º–∏–ª–∞–∑—ã —Å ID {validated_data.amylase_variant_id} –Ω–µ –Ω–∞–π–¥–µ–Ω'}, 
                              status=status.HTTP_400_BAD_REQUEST)
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞–∑–µ—Ü
            with transaction.atomic():
                sample = Sample.objects.create(
                    index_letter_id=validated_data.index_letter_id,
                    strain_id=validated_data.strain_id,
                    storage_id=validated_data.storage_id,
                    original_sample_number=validated_data.original_sample_number,
                    source_id=validated_data.source_id,
                    location_id=validated_data.location_id,
                    appendix_note=validated_data.appendix_note,
                    comment=validated_data.comment,
                    has_photo=validated_data.has_photo,
                    iuk_color_id=validated_data.iuk_color_id,
                    amylase_variant_id=validated_data.amylase_variant_id
                )
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ä–µ–¥—ã —Ä–æ—Å—Ç–∞
                if validated_data.growth_media_ids:
                    for medium_id in validated_data.growth_media_ids:
                        if GrowthMedium.objects.filter(id=medium_id).exists():
                            SampleGrowthMedia.objects.create(sample=sample, growth_medium_id=medium_id)
                
                logger.info(f"Created sample: ID {sample.id}")
                
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞
                sample_data = {
                    'id': sample.id,
                    'original_sample_number': sample.original_sample_number,
                    'strain': {
                        'id': sample.strain.id,
                        'short_code': sample.strain.short_code,
                        'identifier': sample.strain.identifier
                    } if sample.strain else None,
                    'strain_code': sample.strain.short_code if sample.strain else None,
                    'storage': {'id': sample.storage.id, 'name': str(sample.storage)} if sample.storage else None,
                    'storage_name': str(sample.storage) if sample.storage else None,
                    'appendix_note': sample.appendix_note,
                    'comment': sample.comment,
                    'has_photo': sample.has_photo,
                    'created_at': sample.created_at.isoformat() if sample.created_at else None,
                    'updated_at': sample.updated_at.isoformat() if sample.updated_at else None,
                    'growth_media': [
                        {
                            'id': gm.growth_medium.id,
                            'name': gm.growth_medium.name
                        } for gm in sample.growth_media.all()
                    ]
                }
                
                return Response(sample_data, status=status.HTTP_201_CREATED)
        
        except ValidationError as e:
            return Response({
                'error': '–û—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö',
                'details': e.errors()
            }, status=status.HTTP_400_BAD_REQUEST)
        
        except Exception as e:
            logger.error(f"Unexpected error in create_sample: {e}")
            return Response({
                'error': '–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    # GET request - —Å–ø–∏—Å–æ–∫ –æ–±—Ä–∞–∑—Ü–æ–≤
    try:
        page = max(1, int(request.GET.get('page', 1)))
        limit = max(1, min(int(request.GET.get('limit', 50)), 1000))
        offset = (page - 1) * limit
        
        # –ü–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
        search_query = request.GET.get('search', '').strip()
        
        # –§–∏–ª—å—Ç—Ä—ã
        strain_id = request.GET.get('strain_id')
        storage_id = request.GET.get('storage_id')
        source_id = request.GET.get('source_id')
        location_id = request.GET.get('location_id')
        has_photo = request.GET.get('has_photo')
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
        sort_by = request.GET.get('sort_by', 'id')
        sort_direction = request.GET.get('sort_direction', 'asc')
        
        # –ú–∞–ø–ø–∏–Ω–≥ –ø–æ–ª–µ–π –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
        sort_fields_mapping = {
            'id': 'id',
            'original_sample_number': 'original_sample_number',
            'strain': 'strain__short_code',
            'storage': 'storage__box_id',
            'source': 'source__organism_name',
            'location': 'location__name',
            'created_at': 'created_at',
            'updated_at': 'updated_at'
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –ø–æ–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
        if sort_by not in sort_fields_mapping:
            sort_by = 'id'
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
        sort_field = sort_fields_mapping[sort_by]
        if sort_direction.lower() == 'desc':
            sort_field = f'-{sort_field}'
        
        queryset = Sample.objects.select_related(
            'index_letter', 'strain', 'storage', 'source', 'location',
            'iuk_color', 'amylase_variant'
        ).prefetch_related(
            Prefetch('growth_media', queryset=SampleGrowthMedia.objects.select_related('growth_medium'))
        )
        
        if search_query:
            queryset = queryset.filter(
                Q(original_sample_number__icontains=search_query) |
                Q(appendix_note__icontains=search_query) |
                Q(comment__icontains=search_query) |
                Q(strain__short_code__icontains=search_query) |
                Q(strain__identifier__icontains=search_query)
            )
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        if strain_id:
            queryset = queryset.filter(strain_id=strain_id)
        if storage_id:
            queryset = queryset.filter(storage_id=storage_id)
        if source_id:
            queryset = queryset.filter(source_id=source_id)
        if location_id:
            queryset = queryset.filter(location_id=location_id)
        has_photo_value = None
        if has_photo is not None:
            has_photo_value = has_photo.lower() == 'true'
            queryset = queryset.filter(has_photo=has_photo_value)

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É
        queryset = queryset.order_by(sort_field)

        total_count = queryset.count()
        samples = queryset[offset:offset + limit]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        data = []
        for sample in samples:
            sample_data = SampleSchema.model_validate(sample).model_dump()
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–∞—Ö
            sample_data['index_letter'] = sample.index_letter.letter_value if sample.index_letter else None
            sample_data['strain_code'] = sample.strain.short_code if sample.strain else None
            sample_data['strain'] = {'id': sample.strain.id, 'short_code': sample.strain.short_code} if sample.strain else None
            if sample.storage:
                storage_display = str(sample.storage)
                sample_data['storage_name'] = storage_display
                sample_data['storage'] = {
                    'id': sample.storage.id,
                    'box_id': sample.storage.box_id,
                    'cell_id': sample.storage.cell_id,
                    'name': storage_display
                }
            else:
                sample_data['storage_name'] = None
                sample_data['storage'] = None
            sample_data['source_name'] = sample.source.organism_name if sample.source else None
            sample_data['location_name'] = sample.location.name if sample.location else None
            sample_data['iuk_color_name'] = sample.iuk_color.name if sample.iuk_color else None
            sample_data['amylase_variant_name'] = sample.amylase_variant.name if sample.amylase_variant else None
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ä–µ–¥—ã —Ä–æ—Å—Ç–∞
            growth_media = [sgm.growth_medium.name for sgm in sample.growth_media.all()]
            sample_data['growth_media'] = growth_media
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª—è –≤—Ä–µ–º–µ–Ω–∏
            sample_data['created_at'] = sample.created_at.isoformat() if sample.created_at else None
            sample_data['updated_at'] = sample.updated_at.isoformat() if sample.updated_at else None
            
            data.append(sample_data)

        has_next = offset + limit < total_count
        has_prev = page > 1
        shown = len(data)
        total_pages = (total_count + limit - 1) // limit if limit else 0
        pagination = {
            'total': total_count,
            'shown': shown,
            'page': page,
            'limit': limit,
            'total_pages': total_pages,
            'has_next': has_next,
            'has_previous': has_prev,
            'offset': offset
        }
        filters_applied = {
            key: value for key, value in {
                'strain_id': strain_id,
                'storage_id': storage_id,
                'source_id': source_id,
                'location_id': location_id,
                'has_photo': has_photo_value,
            }.items() if value not in (None, '')
        }

        return Response({
            'results': data,
            'samples': data,
            'total': total_count,
            'page': page,
            'limit': limit,
            'has_next': has_next,
            'has_prev': has_prev,
            'has_previous': has_prev,
            'pagination': pagination,
            'shown': shown,
            'search_query': search_query or None,
            'filters_applied': filters_applied or None,
            'sort_by': sort_by,
            'sort_direction': sort_direction
        })
        
    except Exception as e:
        logger.error(f"Error in list_samples: {e}")
        return Response(
            {'error': f'–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –æ–±—Ä–∞–∑—Ü–æ–≤: {str(e)}'},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )


@extend_schema(
    operation_id='samples_search',
    summary='–ü–æ–∏—Å–∫ –æ–±—Ä–∞–∑—Ü–æ–≤',
    description='–ü–æ–∏—Å–∫ –æ–±—Ä–∞–∑—Ü–æ–≤ –ø–æ –Ω–æ–º–µ—Ä—É, —à—Ç–∞–º–º—É, –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—é –∏–ª–∏ –ø—Ä–∏–º–µ—á–∞–Ω–∏—è–º',
    parameters=[
        OpenApiParameter(name='search', type=str, description='–°—Ç—Ä–æ–∫–∞ –ø–æ–∏—Å–∫–∞'),
        OpenApiParameter(name='limit', type=int, description='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤'),
        OpenApiParameter(name='strain_id', type=int, description='–§–∏–ª—å—Ç—Ä –ø–æ —à—Ç–∞–º–º—É'),
        OpenApiParameter(name='storage_id', type=int, description='–§–∏–ª—å—Ç—Ä –ø–æ –º–µ—Å—Ç—É —Ö—Ä–∞–Ω–µ–Ω–∏—è'),
        OpenApiParameter(name='has_photo', type=bool, description='–§–∏–ª—å—Ç—Ä –ø–æ –Ω–∞–ª–∏—á–∏—é —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π'),
    ],
    responses={200: OpenApiResponse(description='–°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤')}
)
@api_view(['GET'])
def search_samples(request):
    """–ü–æ–∏—Å–∫ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –∞–≤—Ç–æ–∫–æ–º–ø–ª–∏—Ç–∞ –∏ –±—ã—Å—Ç—Ä—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤."""

    try:
        query = (request.GET.get('search') or '').strip()
        limit_raw = request.GET.get('limit', 10)

        try:
            limit = int(limit_raw)
        except (TypeError, ValueError):
            limit = 10

        limit = max(1, min(limit, 100))

        queryset = Sample.objects.select_related(
            'strain', 'storage', 'source', 'location', 'index_letter',
            'iuk_color', 'amylase_variant'
        )

        if query:
            search_filter = (
                Q(original_sample_number__icontains=query)
                | Q(appendix_note__icontains=query)
                | Q(comment__icontains=query)
                | Q(strain__short_code__icontains=query)
                | Q(strain__identifier__icontains=query)
                | Q(storage__box_id__icontains=query)
                | Q(storage__cell_id__icontains=query)
                | Q(source__organism_name__icontains=query)
                | Q(location__name__icontains=query)
            )
            queryset = queryset.filter(search_filter)

        strain_id = request.GET.get('strain_id')
        storage_id = request.GET.get('storage_id')
        has_photo = request.GET.get('has_photo')

        if strain_id:
            queryset = queryset.filter(strain_id=strain_id)
        if storage_id:
            queryset = queryset.filter(storage_id=storage_id)
        if has_photo is not None:
            has_photo_flag = _coerce_to_bool(has_photo)
            if has_photo_flag is not None:
                queryset = queryset.filter(has_photo=has_photo_flag)

        samples = list(queryset.order_by('original_sample_number', 'id')[:limit])

        results = []
        for sample in samples:
            result = {
                'id': sample.id,
                'original_sample_number': sample.original_sample_number,
                'has_photo': sample.has_photo,
                'appendix_note': sample.appendix_note,
                'comment': sample.comment,
                'created_at': sample.created_at.isoformat() if sample.created_at else None,
                'updated_at': sample.updated_at.isoformat() if sample.updated_at else None,
            }

            if sample.strain:
                result['strain'] = {
                    'id': sample.strain.id,
                    'short_code': sample.strain.short_code,
                    'identifier': sample.strain.identifier,
                }

            if sample.storage:
                result['storage'] = {
                    'id': sample.storage.id,
                    'box_id': sample.storage.box_id,
                    'cell_id': sample.storage.cell_id,
                }

            if sample.source:
                result['source'] = {
                    'id': sample.source.id,
                    'organism_name': sample.source.organism_name,
                }

            if sample.location:
                result['location'] = {
                    'id': sample.location.id,
                    'name': sample.location.name,
                }

            results.append(result)

        return Response(results)

    except Exception as exc:
        logger.error(f"Error in search_samples: {exc}")
        return Response(
            {'error': f'–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –æ–±—Ä–∞–∑—Ü–æ–≤: {exc}'},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR,
        )


@extend_schema(
    operation_id="sample_detail",
    summary="–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–∞",
    description="–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–∞ –ø–æ ID",
    responses={
        200: OpenApiResponse(description="–î–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–∑—Ü–∞"),
        404: OpenApiResponse(description="–û–±—Ä–∞–∑–µ—Ü –Ω–µ –Ω–∞–π–¥–µ–Ω"),
        500: OpenApiResponse(description="–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"),
    }
)
@api_view(['GET'])
def get_sample(request, sample_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–∞ –ø–æ ID"""
    try:
        sample = Sample.objects.select_related(
            'index_letter', 'strain', 'storage', 'source', 'location',
            'iuk_color', 'amylase_variant'
        ).prefetch_related(
            Prefetch('growth_media', queryset=SampleGrowthMedia.objects.select_related('growth_medium')),
            'photos'
        ).get(id=sample_id)
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
        data = {
            'id': sample.id,
            'original_sample_number': sample.original_sample_number,
            'appendix_note': sample.appendix_note,
            'comment': sample.comment,
            'has_photo': sample.has_photo,
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        if sample.index_letter:
            data['index_letter'] = {
                'id': sample.index_letter.id,
                'letter_value': sample.index_letter.letter_value
            }
        else:
            data['index_letter'] = None
            
        if sample.strain:
            data['strain'] = {
                'id': sample.strain.id,
                'short_code': sample.strain.short_code,
                'identifier': sample.strain.identifier,
                'rrna_taxonomy': sample.strain.rrna_taxonomy
            }
        else:
            data['strain'] = None
            
        if sample.storage:
            data['storage'] = {
                'id': sample.storage.id,
                'box_id': sample.storage.box_id,
                'cell_id': sample.storage.cell_id
            }
        else:
            data['storage'] = None
            
        if sample.source:
            data['source'] = {
                'id': sample.source.id,
                'organism_name': sample.source.organism_name,
                'source_type': sample.source.source_type.name,
                'category': sample.source.category.name
            }
        else:
            data['source'] = None
            
        if sample.location:
            data['location'] = {
                'id': sample.location.id,
                'name': sample.location.name
            }
        else:
            data['location'] = None
            
        if sample.iuk_color:
            data['iuk_color'] = {
                'id': sample.iuk_color.id,
                'name': sample.iuk_color.name,
                'hex_code': sample.iuk_color.hex_code
            }
        else:
            data['iuk_color'] = None
            
        if sample.amylase_variant:
            data['amylase_variant'] = {
                'id': sample.amylase_variant.id,
                'name': sample.amylase_variant.name,
                'description': sample.amylase_variant.description
            }
        else:
            data['amylase_variant'] = None
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ä–µ–¥—ã —Ä–æ—Å—Ç–∞
        growth_media = []
        for sgm in sample.growth_media.all():
            growth_media.append({
                'id': sgm.growth_medium.id,
                'name': sgm.growth_medium.name,
                'description': sgm.growth_medium.description
            })
        data['growth_media'] = growth_media
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        data['created_at'] = sample.created_at.isoformat() if sample.created_at else None
        data['updated_at'] = sample.updated_at.isoformat() if sample.updated_at else None
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
        photos = []
        for photo in sample.photos.all():
            photos.append({
                'id': photo.id,
                'image': photo.image.url if photo.image else None,
                'uploaded_at': photo.uploaded_at.isoformat() if photo.uploaded_at else None
            })
        data['photos'] = photos
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        characteristics = {}
        sample_characteristics = SampleCharacteristicValue.objects.filter(
            sample=sample
        ).select_related('characteristic')
        
        for char_value in sample_characteristics:
            char = char_value.characteristic
            value_data = {
                'characteristic_id': char.id,
                'characteristic_name': char.name,
                'characteristic_type': char.characteristic_type,
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
            if char.characteristic_type == 'boolean':
                value_data['value'] = char_value.boolean_value
            elif char.characteristic_type == 'text':
                value_data['value'] = char_value.text_value
            elif char.characteristic_type == 'select':
                value_data['value'] = char_value.select_value
            else:
                value_data['value'] = None
                
            characteristics[char.name] = value_data
            
        data['characteristics'] = characteristics
        
        return Response(data)
    except Sample.DoesNotExist:
        return Response(
            {'error': f'–û–±—Ä–∞–∑–µ—Ü —Å ID {sample_id} –Ω–µ –Ω–∞–π–¥–µ–Ω'},
            status=status.HTTP_404_NOT_FOUND
        )
    except Exception as e:
        logger.error(f"Error in get_sample: {e}")
        return Response(
            {'error': f'–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±—Ä–∞–∑—Ü–∞: {str(e)}'},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )


@api_view(['POST'])
@csrf_exempt
def create_sample(request):
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞"""
    try:
        validated_data = CreateSampleSchema.model_validate(request.data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        if validated_data.index_letter_id and not IndexLetter.objects.filter(id=validated_data.index_letter_id).exists():
            return Response({'error': f'–ò–Ω–¥–µ–∫—Å–Ω–∞—è –±—É–∫–≤–∞ —Å ID {validated_data.index_letter_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}, 
                          status=status.HTTP_400_BAD_REQUEST)
        
        if validated_data.strain_id and not Strain.objects.filter(id=validated_data.strain_id).exists():
            return Response({'error': f'–®—Ç–∞–º–º —Å ID {validated_data.strain_id} –Ω–µ –Ω–∞–π–¥–µ–Ω'}, 
                          status=status.HTTP_400_BAD_REQUEST)
        
        if validated_data.storage_id and not Storage.objects.filter(id=validated_data.storage_id).exists():
            return Response({'error': f'–•—Ä–∞–Ω–∏–ª–∏—â–µ —Å ID {validated_data.storage_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}, 
                          status=status.HTTP_400_BAD_REQUEST)
        
        if validated_data.source_id and not Source.objects.filter(id=validated_data.source_id).exists():
            return Response({'error': f'–ò—Å—Ç–æ—á–Ω–∏–∫ —Å ID {validated_data.source_id} –Ω–µ –Ω–∞–π–¥–µ–Ω'}, 
                          status=status.HTTP_400_BAD_REQUEST)
        
        if validated_data.location_id and not Location.objects.filter(id=validated_data.location_id).exists():
            return Response({'error': f'–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ —Å ID {validated_data.location_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}, 
                          status=status.HTTP_400_BAD_REQUEST)
        
        if validated_data.iuk_color_id and not IUKColor.objects.filter(id=validated_data.iuk_color_id).exists():
            return Response({'error': f'–¶–≤–µ—Ç –ò–£–ö —Å ID {validated_data.iuk_color_id} –Ω–µ –Ω–∞–π–¥–µ–Ω'}, 
                          status=status.HTTP_400_BAD_REQUEST)
        
        if validated_data.amylase_variant_id and not AmylaseVariant.objects.filter(id=validated_data.amylase_variant_id).exists():
            return Response({'error': f'–í–∞—Ä–∏–∞–Ω—Ç –∞–º–∏–ª–∞–∑—ã —Å ID {validated_data.amylase_variant_id} –Ω–µ –Ω–∞–π–¥–µ–Ω'}, 
                          status=status.HTTP_400_BAD_REQUEST)
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞–∑–µ—Ü
        with transaction.atomic():
            sample = Sample.objects.create(
                index_letter_id=validated_data.index_letter_id,
                strain_id=validated_data.strain_id,
                storage_id=validated_data.storage_id,
                original_sample_number=validated_data.original_sample_number,
                source_id=validated_data.source_id,
                location_id=validated_data.location_id,
                appendix_note=validated_data.appendix_note,
                comment=validated_data.comment,
                has_photo=validated_data.has_photo,
                iuk_color_id=validated_data.iuk_color_id,
                amylase_variant_id=validated_data.amylase_variant_id
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ä–µ–¥—ã —Ä–æ—Å—Ç–∞
            if validated_data.growth_media_ids:
                for medium_id in validated_data.growth_media_ids:
                    if GrowthMedium.objects.filter(id=medium_id).exists():
                        SampleGrowthMedia.objects.create(sample=sample, growth_medium_id=medium_id)
            
            logger.info(f"Created sample: ID {sample.id}")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞
        sample_data = {
            'id': sample.id,
            'original_sample_number': sample.original_sample_number,
            'strain': {
                'id': sample.strain.id,
                'short_code': sample.strain.short_code,
                'identifier': sample.strain.identifier
            } if sample.strain else None,
            'strain_code': sample.strain.short_code if sample.strain else None,
            'storage': {'id': sample.storage.id, 'name': str(sample.storage)} if sample.storage else None,
            'storage_name': str(sample.storage) if sample.storage else None,
            'appendix_note': sample.appendix_note,
            'comment': sample.comment,
            'has_photo': sample.has_photo,
            'created_at': sample.created_at.isoformat() if sample.created_at else None,
            'updated_at': sample.updated_at.isoformat() if sample.updated_at else None,
            'growth_media': [
                {
                    'id': gm.growth_medium.id,
                    'name': gm.growth_medium.name
                } for gm in sample.growth_media.all()
            ]
        }
        
        return Response(sample_data, status=status.HTTP_201_CREATED)
    
    except ValidationError as e:
        return Response({
            'error': '–û—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö',
            'details': e.errors()
        }, status=status.HTTP_400_BAD_REQUEST)
    
    except IntegrityError as e:
        logger.warning(f"IntegrityError in create_sample: {e}")
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –ø—ã—Ç–∞–µ–º—Å—è —Å–Ω–æ–≤–∞
        reset_sequence(Sample)
        try:
            with transaction.atomic():
                sample = Sample.objects.create(
                    index_letter_id=validated_data.index_letter_id,
                    strain_id=validated_data.strain_id,
                    storage_id=validated_data.storage_id,
                    original_sample_number=validated_data.original_sample_number,
                    source_id=validated_data.source_id,
                    location_id=validated_data.location_id,
                    appendix_note=validated_data.appendix_note,
                    comment=validated_data.comment,
                    has_photo=validated_data.has_photo,
                    iuk_color_id=validated_data.iuk_color_id,
                    amylase_variant_id=validated_data.amylase_variant_id
                )
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ä–µ–¥—ã —Ä–æ—Å—Ç–∞
                if validated_data.growth_media_ids:
                    for medium_id in validated_data.growth_media_ids:
                        if GrowthMedium.objects.filter(id=medium_id).exists():
                            SampleGrowthMedia.objects.create(sample=sample, growth_medium_id=medium_id)
                
                logger.info(f"Created sample after sequence reset: ID {sample.id}")
                
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞
                sample_data = {
                    'id': sample.id,
                    'original_sample_number': sample.original_sample_number,
                    'strain': {
                        'id': sample.strain.id,
                        'short_code': sample.strain.short_code,
                        'identifier': sample.strain.identifier
                    } if sample.strain else None,
                    'strain_code': sample.strain.short_code if sample.strain else None,
                    'storage': {'id': sample.storage.id, 'name': str(sample.storage)} if sample.storage else None,
                    'storage_name': str(sample.storage) if sample.storage else None,
                    'appendix_note': sample.appendix_note,
                    'comment': sample.comment,
                    'has_photo': sample.has_photo,
                    'created_at': sample.created_at.isoformat() if sample.created_at else None,
                    'updated_at': sample.updated_at.isoformat() if sample.updated_at else None,
                    'growth_media': [
                        {
                            'id': gm.growth_medium.id,
                            'name': gm.growth_medium.name
                        } for gm in sample.growth_media.all()
                    ]
                }
                
                return Response(sample_data, status=status.HTTP_201_CREATED)
                
        except Exception as retry_e:
            logger.error(f"Failed to create sample even after sequence reset: {retry_e}")
            return Response({
                'error': '–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –æ–±—Ä–∞–∑–µ—Ü'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    except Exception as e:
        logger.error(f"Unexpected error in create_sample: {e}")
        return Response({
            'error': '–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['PUT'])
@csrf_exempt
def update_sample(request, sample_id):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–∞"""

    logger.info(f"üîß update_sample called for sample {sample_id}")
    logger.info(f"üîß Request data: {request.data}")
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –æ–±—Ä–∞–∑–µ—Ü
        try:
            sample = Sample.objects.get(id=sample_id)
        except Sample.DoesNotExist:
            return Response({
                'error': f'–û–±—Ä–∞–∑–µ—Ü —Å ID {sample_id} –Ω–µ –Ω–∞–π–¥–µ–Ω'
            }, status=status.HTTP_404_NOT_FOUND)
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        validated_data = UpdateSampleSchema.model_validate(request.data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ create_sample)
        # ... (–∫–æ–¥ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–Ω–∞–ª–æ–≥–∏—á–µ–Ω create_sample)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–∞
        with transaction.atomic():
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –æ—Ç–¥–µ–ª—å–Ω–æ –ø–µ—Ä–µ–¥ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –∏–∑ model_dump
            characteristics_data = validated_data.characteristics
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—è –æ–±—Ä–∞–∑—Ü–∞, –∏—Å–∫–ª—é—á–∞—è has_photo (—É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ —Å–∏–≥–Ω–∞–ª—ã) –∏ characteristics
            for field, value in validated_data.model_dump(exclude={'growth_media_ids', 'has_photo', 'characteristics'}).items():
                if value is not None:  # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ-None –∑–Ω–∞—á–µ–Ω–∏—è
                    setattr(sample, field, value)
            sample.save()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥—ã —Ä–æ—Å—Ç–∞
            SampleGrowthMedia.objects.filter(sample=sample).delete()
            if validated_data.growth_media_ids:
                for medium_id in validated_data.growth_media_ids:
                    if GrowthMedium.objects.filter(id=medium_id).exists():
                        SampleGrowthMedia.objects.create(sample=sample, growth_medium_id=medium_id)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            if characteristics_data:
                logger.info(f"üîß Processing characteristics: {characteristics_data}")
                for char_name, char_data in characteristics_data.items():
                    try:
                        characteristic = SampleCharacteristic.objects.get(name=char_name)
                        
                        # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
                        char_value, created = SampleCharacteristicValue.objects.get_or_create(
                            sample=sample,
                            characteristic=characteristic,
                            defaults={}
                        )
                        
                        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
                        if characteristic.characteristic_type == 'boolean':
                            char_value.boolean_value = bool(char_data.get('value', False))
                            char_value.text_value = None
                            char_value.select_value = None
                        elif characteristic.characteristic_type == 'text':
                            char_value.text_value = str(char_data.get('value', ''))
                            char_value.boolean_value = None
                            char_value.select_value = None
                        elif characteristic.characteristic_type == 'select':
                            char_value.select_value = str(char_data.get('value', ''))
                            char_value.boolean_value = None
                            char_value.text_value = None
                        
                        char_value.save()
                        logger.info(f"üîß Saved characteristic '{char_name}' with value: {char_data}")
                        
                    except SampleCharacteristic.DoesNotExist:
                        logger.warning(f"üîß Characteristic '{char_name}' not found, skipping")
                        continue
                    except Exception as e:
                        logger.error(f"Error processing characteristic '{char_name}': {e}")
                        continue
            
            logger.info(f"Updated sample: ID {sample.id}")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞
        sample_data = {
            'id': sample.id,
            'original_sample_number': sample.original_sample_number,
            'strain': {
                'id': sample.strain.id,
                'short_code': sample.strain.short_code,
                'identifier': sample.strain.identifier
            } if sample.strain else None,
            'strain_code': sample.strain.short_code if sample.strain else None,
            'storage': str(sample.storage) if sample.storage else None,
            'storage_name': str(sample.storage) if sample.storage else None,
            'appendix_note': sample.appendix_note,
            'comment': sample.comment,
            'has_photo': sample.has_photo,
            'created_at': sample.created_at.isoformat() if sample.created_at else None,
            'updated_at': sample.updated_at.isoformat() if sample.updated_at else None,
            'growth_media': [
                {
                    'id': gm.growth_medium.id,
                    'name': gm.growth_medium.name
                } for gm in sample.growth_media.all()
            ]
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤ –æ—Ç–≤–µ—Ç
        characteristics = {}
        sample_characteristics = SampleCharacteristicValue.objects.filter(
            sample=sample
        ).select_related('characteristic')
        
        for char_value in sample_characteristics:
            char = char_value.characteristic
            value_data = {
                'characteristic_id': char.id,
                'characteristic_name': char.name,
                'characteristic_type': char.characteristic_type,
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
            if char.characteristic_type == 'boolean':
                value_data['value'] = char_value.boolean_value
            elif char.characteristic_type == 'text':
                value_data['value'] = char_value.text_value
            elif char.characteristic_type == 'select':
                value_data['value'] = char_value.select_value
            else:
                value_data['value'] = None
                
            characteristics[char.name] = value_data
            
        sample_data['characteristics'] = characteristics
        
        return Response(sample_data, status=status.HTTP_200_OK)
    
    except ValidationError as e:
        return Response({
            'error': '–û—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö',
            'details': e.errors()
        }, status=status.HTTP_400_BAD_REQUEST)
    
    except Exception as e:
        logger.error(f"Unexpected error in update_sample: {e}")
        return Response({
            'error': '–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['DELETE'])
@csrf_exempt
def delete_sample(request, sample_id):
    """–£–¥–∞–ª–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–∞"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –æ–±—Ä–∞–∑–µ—Ü
        try:
            sample = Sample.objects.get(id=sample_id)
        except Sample.DoesNotExist:
            return Response({
                'error': f'–û–±—Ä–∞–∑–µ—Ü —Å ID {sample_id} –Ω–µ –Ω–∞–π–¥–µ–Ω'
            }, status=status.HTTP_404_NOT_FOUND)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—Ä–∞–∑—Ü–µ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
        sample_info = {
            'id': sample.id,
            'original_sample_number': sample.original_sample_number
        }
        
        # –£–¥–∞–ª—è–µ–º –æ–±—Ä–∞–∑–µ—Ü (—Å–≤—è–∑–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã —É–¥–∞–ª—è—Ç—Å—è –∫–∞—Å–∫–∞–¥–Ω–æ)
        with transaction.atomic():
            sample.delete()
            logger.info(f"Deleted sample: ID {sample_info['id']}")
        
        return Response({
            'message': f"–û–±—Ä–∞–∑–µ—Ü ID {sample_info['id']} —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω",
            'deleted_sample': sample_info
        }, status=status.HTTP_200_OK)
        
    except Exception as e:
        logger.error(f"Unexpected error in delete_sample: {e}")
        return Response({
            'error': '–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@extend_schema(
    summary='–ú–∞—Å—Å–æ–≤–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–æ–≤',
    description='–£–¥–∞–ª—è–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –ø–æ —Å–ø–∏—Å–∫—É ID —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–π',
    responses={
        200: OpenApiResponse(description='–û–±—Ä–∞–∑—Ü—ã —É–¥–∞–ª–µ–Ω—ã'),
        400: OpenApiResponse(description='–û—à–∏–±–æ—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å'),
        404: OpenApiResponse(description='–û–±—Ä–∞–∑–µ—Ü –Ω–µ –Ω–∞–π–¥–µ–Ω'),
    }
)
@api_view(['POST'])
@csrf_exempt
def bulk_delete_samples(request):
    """–ú–∞—Å—Å–æ–≤–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–æ–≤ c –∞—É–¥–∏—Ç–æ–º –∏–∑–º–µ–Ω–µ–Ω–∏–π."""

    try:
        payload = request.data if isinstance(request.data, dict) else {}
        sample_ids = _parse_ids(payload.get('sample_ids') or payload.get('ids'))

        if not sample_ids:
            return Response(
                {'error': '–ù–µ –ø–µ—Ä–µ–¥–∞–Ω—ã ID –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è'},
                status=status.HTTP_400_BAD_REQUEST,
            )

        existing_samples = list(
            Sample.objects.filter(id__in=sample_ids)
            .select_related('strain', 'storage')
            .order_by('id')
        )

        found_ids = {sample.id for sample in existing_samples}
        missing_ids = sorted(set(sample_ids) - found_ids)
        if missing_ids:
            return Response(
                {'error': f'–û–±—Ä–∞–∑—Ü—ã —Å ID {missing_ids} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã'},
                status=status.HTTP_404_NOT_FOUND,
            )

        batch_id = generate_batch_id()
        deleted_snapshot = []

        with transaction.atomic():
            for sample in existing_samples:
                deleted_snapshot.append(
                    {
                        'id': sample.id,
                        'original_sample_number': sample.original_sample_number,
                        'strain_short_code': sample.strain.short_code if sample.strain else None,
                        'storage': (
                            f"{sample.storage.box_id}-{sample.storage.cell_id}"
                            if sample.storage
                            else None
                        ),
                    }
                )

                log_change(
                    request=request,
                    content_type='sample',
                    object_id=sample.id,
                    action='BULK_DELETE',
                    old_values=model_to_dict(sample),
                    new_values=None,
                    comment=f'–ú–∞—Å—Å–æ–≤–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ {len(sample_ids)} –æ–±—Ä–∞–∑—Ü–æ–≤',
                    batch_id=batch_id,
                )

            deleted_count = Sample.objects.filter(id__in=sample_ids).delete()[0]

        logger.info(
            "Bulk deleted %s samples (batch=%s): %s",
            deleted_count,
            batch_id,
            sample_ids,
        )

        return Response(
            {
                'message': f'–£–¥–∞–ª–µ–Ω–æ {deleted_count} –æ–±—Ä–∞–∑—Ü–æ–≤',
                'deleted_count': deleted_count,
                'deleted_samples': deleted_snapshot,
                'batch_id': batch_id,
            }
        )

    except Exception as exc:
        logger.error(f"Error in bulk_delete_samples: {exc}")
        return Response(
            {'error': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –º–∞—Å—Å–æ–≤–æ–º —É–¥–∞–ª–µ–Ω–∏–∏: {exc}'},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR,
        )


@extend_schema(
    summary='–ú–∞—Å—Å–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–æ–≤',
    description='–û–±–Ω–æ–≤–ª—è–µ—Ç —É–∫–∞–∑–∞–Ω–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –Ω–∞–±–æ—Ä–∞ –æ–±—Ä–∞–∑—Ü–æ–≤, –≤–∫–ª—é—á–∞—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏',
    responses={
        200: OpenApiResponse(description='–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ'),
        400: OpenApiResponse(description='–û—à–∏–±–æ—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å'),
        404: OpenApiResponse(description='–û–±—Ä–∞–∑–µ—Ü –Ω–µ –Ω–∞–π–¥–µ–Ω'),
    }
)
@api_view(['POST'])
@csrf_exempt
def bulk_update_samples(request):
    """–ú–∞—Å—Å–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–æ–≤ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫."""

    try:
        payload = request.data if isinstance(request.data, dict) else {}
        sample_ids = _parse_ids(payload.get('sample_ids') or payload.get('ids'))
        update_data = payload.get('update_data') or payload.get('data') or {}

        if not sample_ids:
            return Response(
                {'error': '–ù–µ –ø–µ—Ä–µ–¥–∞–Ω—ã ID –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è'},
                status=status.HTTP_400_BAD_REQUEST,
            )

        if not isinstance(update_data, dict) or not update_data:
            return Response(
                {'error': '–ù–µ –ø–µ—Ä–µ–¥–∞–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è'},
                status=status.HTTP_400_BAD_REQUEST,
            )

        existing_samples = list(
            Sample.objects.filter(id__in=sample_ids)
            .select_related('strain')
            .order_by('id')
        )

        found_ids = {sample.id for sample in existing_samples}
        missing_ids = sorted(set(sample_ids) - found_ids)
        if missing_ids:
            return Response(
                {'error': f'–û–±—Ä–∞–∑—Ü—ã —Å ID {missing_ids} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã'},
                status=status.HTTP_404_NOT_FOUND,
            )

        direct_updates: Dict[str, Optional[object]] = {}
        characteristic_updates: Dict[str, Optional[bool]] = {}

        for field, raw_value in update_data.items():
            if field == 'has_photo':
                coerced = _coerce_to_bool(raw_value)
                if coerced is None:
                    return Response(
                        {'error': "–ü–æ–ª–µ 'has_photo' –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±—É–ª–µ–≤—ã–º"},
                        status=status.HTTP_400_BAD_REQUEST,
                    )
                direct_updates[field] = coerced

            elif field in {'iuk_color_id', 'amylase_variant_id'}:
                if raw_value in {None, '', 'null'}:
                    direct_updates[field] = None
                else:
                    try:
                        related_id = int(raw_value)
                    except (TypeError, ValueError):
                        return Response(
                            {'error': f"–ü–æ–ª–µ '{field}' –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —á–∏—Å–ª–æ–≤–æ–π ID"},
                            status=status.HTTP_400_BAD_REQUEST,
                        )

                    model_cls = IUKColor if field == 'iuk_color_id' else AmylaseVariant
                    if not model_cls.objects.filter(id=related_id).exists():
                        return Response(
                            {'error': f"–ó–∞–ø–∏—Å—å —Å ID {related_id} –¥–ª—è '{field}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"},
                            status=status.HTTP_400_BAD_REQUEST,
                        )
                    direct_updates[field] = related_id

            elif field in BOOLEAN_CHARACTERISTIC_FIELDS:
                coerced = _coerce_to_bool(raw_value)
                if coerced is None:
                    return Response(
                        {'error': f"–ü–æ–ª–µ '{field}' –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±—É–ª–µ–≤—ã–º"},
                        status=status.HTTP_400_BAD_REQUEST,
                    )
                characteristic_updates[field] = coerced

        if not direct_updates and not characteristic_updates:
            return Response(
                {'error': '–ù–µ—Ç –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –ø–æ–ª–µ–π –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è'},
                status=status.HTTP_400_BAD_REQUEST,
            )

        characteristics_map: Dict[str, SampleCharacteristic] = {}
        if characteristic_updates:
            search_names = set()
            for slug in characteristic_updates.keys():
                search_names.update(BOOLEAN_CHARACTERISTIC_FIELDS.get(slug, (slug,)))

            characteristic_qs = SampleCharacteristic.objects.filter(
                Q(name__in=search_names) | Q(display_name__in=search_names)
            )

            for characteristic in characteristic_qs:
                for slug, aliases in BOOLEAN_CHARACTERISTIC_FIELDS.items():
                    if characteristic.name in aliases or characteristic.display_name in aliases:
                        characteristics_map.setdefault(slug, characteristic)

            missing_chars = [slug for slug in characteristic_updates if slug not in characteristics_map]
            if missing_chars:
                return Response(
                    {
                        'error': '–ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã',
                        'missing_characteristics': missing_chars,
                    },
                    status=status.HTTP_400_BAD_REQUEST,
                )

        batch_id = generate_batch_id()
        updated_fields = list(direct_updates.keys()) + list(characteristic_updates.keys())

        with transaction.atomic():
            for sample in existing_samples:
                old_values = model_to_dict(sample)
                new_values: Dict[str, object] = {}

                if direct_updates:
                    for field, value in direct_updates.items():
                        setattr(sample, field, value)
                    sample.save(update_fields=list(direct_updates.keys()))
                    new_values.update(direct_updates)

                if characteristic_updates:
                    char_changes: Dict[str, bool] = {}
                    for slug, flag in characteristic_updates.items():
                        characteristic = characteristics_map[slug]
                        char_value = SampleCharacteristicValue.objects.filter(
                            sample=sample,
                            characteristic=characteristic,
                        ).first()

                        if flag:
                            if char_value:
                                if char_value.boolean_value is not True:
                                    char_value.boolean_value = True
                                    char_value.text_value = None
                                    char_value.select_value = None
                                    char_value.save(update_fields=['boolean_value', 'text_value', 'select_value'])
                            else:
                                SampleCharacteristicValue.objects.create(
                                    sample=sample,
                                    characteristic=characteristic,
                                    boolean_value=True,
                                )
                            char_changes[slug] = True
                        else:
                            if char_value:
                                char_value.delete()
                            char_changes[slug] = False

                    if char_changes:
                        new_values['characteristics'] = char_changes

                if new_values:
                    log_change(
                        request=request,
                        content_type='sample',
                        object_id=sample.id,
                        action='BULK_UPDATE',
                        old_values=old_values,
                        new_values=new_values,
                        comment=f"–ú–∞—Å—Å–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–ª–µ–π: {', '.join(updated_fields)}",
                        batch_id=batch_id,
                    )

        logger.info(
            "Bulk updated samples (batch=%s): ids=%s fields=%s",
            batch_id,
            sample_ids,
            updated_fields,
        )

        return Response(
            {
                'message': f'–û–±–Ω–æ–≤–ª–µ–Ω–æ {len(existing_samples)} –æ–±—Ä–∞–∑—Ü–æ–≤',
                'updated_count': len(existing_samples),
                'updated_fields': updated_fields,
                'batch_id': batch_id,
            }
        )

    except Exception as exc:
        logger.error(f"Error in bulk_update_samples: {exc}")
        return Response(
            {'error': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –º–∞—Å—Å–æ–≤–æ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏: {exc}'},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR,
        )


@extend_schema(
    summary='–≠–∫—Å–ø–æ—Ä—Ç –æ–±—Ä–∞–∑—Ü–æ–≤',
    description='–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –æ–±—Ä–∞–∑—Ü—ã –≤ CSV, JSON –∏–ª–∏ Excel —Å –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏',
    responses={200: OpenApiResponse(description='–§–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º –æ–±—Ä–∞–∑—Ü–æ–≤')}
)
@api_view(['GET', 'POST'])
@csrf_exempt
def export_samples(request):
    """–≠–∫—Å–ø–æ—Ä—Ç –æ–±—Ä–∞–∑—Ü–æ–≤ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã."""

    try:
        import csv
        import json
        from io import StringIO, BytesIO

        params = request.data if request.method == 'POST' else request.GET

        sample_ids = _parse_ids(params.get('sample_ids') or params.get('ids'))
        format_type = (params.get('format') or 'csv').lower()
        fields_value = params.get('fields')
        include_related = params.get('include_related', 'true')

        queryset = Sample.objects.all()

        if sample_ids:
            queryset = queryset.filter(id__in=sample_ids)
        else:
            search_query = (params.get('search') or '').strip()
            if search_query:
                queryset = queryset.filter(
                    Q(original_sample_number__icontains=search_query)
                    | Q(appendix_note__icontains=search_query)
                    | Q(comment__icontains=search_query)
                    | Q(strain__short_code__icontains=search_query)
                    | Q(strain__identifier__icontains=search_query)
                    | Q(storage__box_id__icontains=search_query)
                )

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
        filter_map = {
            'strain_id': 'strain_id',
            'storage_id': 'storage_id',
            'source_id': 'source_id',
            'location_id': 'location_id',
            'iuk_color_id': 'iuk_color_id',
            'amylase_variant_id': 'amylase_variant_id',
        }
        for param, field_name in filter_map.items():
            value = params.get(param)
            if value not in (None, ''):
                queryset = queryset.filter(**{field_name: value})

        has_photo_value = params.get('has_photo')
        if has_photo_value not in (None, ''):
            coerced = _coerce_to_bool(has_photo_value)
            if coerced is not None:
                queryset = queryset.filter(has_photo=coerced)

        queryset = queryset.order_by('id')

        if str(include_related).lower() in {'true', '1', 'yes', 'y'}:
            queryset = queryset.select_related(
                'strain', 'storage', 'source', 'location', 'iuk_color', 'amylase_variant'
            ).prefetch_related(
                Prefetch('growth_media', queryset=SampleGrowthMedia.objects.select_related('growth_medium'))
            )

        available_fields = {
            'id': 'ID',
            'original_sample_number': '–ù–æ–º–µ—Ä –æ–±—Ä–∞–∑—Ü–∞',
            'strain_short_code': '–ö–æ–¥ —à—Ç–∞–º–º–∞',
            'strain_identifier': '–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —à—Ç–∞–º–º–∞',
            'storage_cell': '–Ø—á–µ–π–∫–∞ —Ö—Ä–∞–Ω–µ–Ω–∏—è',
            'has_photo': '–ï—Å—Ç—å —Ñ–æ—Ç–æ',
            'source_organism': '–ò—Å—Ç–æ—á–Ω–∏–∫',
            'location_name': '–õ–æ–∫–∞—Ü–∏—è',
            'iuk_color': '–¶–≤–µ—Ç –ò–£–ö',
            'amylase_variant': '–í–∞—Ä–∏–∞–Ω—Ç –∞–º–∏–ª–∞–∑—ã',
            'growth_media': '–°—Ä–µ–¥—ã —Ä–æ—Å—Ç–∞',
            'created_at': '–°–æ–∑–¥–∞–Ω',
            'updated_at': '–û–±–Ω–æ–≤–ª–µ–Ω',
        }

        if fields_value:
            raw_fields = [item.strip() for item in str(fields_value).split(',') if item.strip()]
            export_fields = [field for field in raw_fields if field in available_fields]
        else:
            export_fields = list(available_fields.keys())

        if not export_fields:
            return Response(
                {'error': '–ù–µ —É–∫–∞–∑–∞–Ω—ã –¥–æ–ø—É—Å—Ç–∏–º—ã–µ –ø–æ–ª—è –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞'},
                status=status.HTTP_400_BAD_REQUEST,
            )

        rows = []
        for sample in queryset:
            row = {}
            for field in export_fields:
                header = available_fields[field]
                if field == 'id':
                    row[header] = sample.id
                elif field == 'original_sample_number':
                    row[header] = sample.original_sample_number or ''
                elif field == 'strain_short_code':
                    row[header] = sample.strain.short_code if sample.strain else ''
                elif field == 'strain_identifier':
                    row[header] = sample.strain.identifier if sample.strain else ''
                elif field == 'storage_cell':
                    row[header] = (
                        f"{sample.storage.box_id}:{sample.storage.cell_id}"
                        if sample.storage
                        else ''
                    )
                elif field == 'has_photo':
                    row[header] = '–î–∞' if sample.has_photo else '–ù–µ—Ç'
                elif field == 'source_organism':
                    row[header] = sample.source.organism_name if sample.source else ''
                elif field == 'location_name':
                    row[header] = sample.location.name if sample.location else ''
                elif field == 'iuk_color':
                    row[header] = sample.iuk_color.name if sample.iuk_color else ''
                elif field == 'amylase_variant':
                    row[header] = sample.amylase_variant.name if sample.amylase_variant else ''
                elif field == 'growth_media':
                    if hasattr(sample, 'growth_media'):
                        names = [gm.growth_medium.name for gm in sample.growth_media.all()]
                        row[header] = ', '.join(names)
                    else:
                        row[header] = ''
                elif field == 'created_at':
                    row[header] = (
                        sample.created_at.strftime('%Y-%m-%d %H:%M:%S')
                        if sample.created_at
                        else ''
                    )
                elif field == 'updated_at':
                    row[header] = (
                        sample.updated_at.strftime('%Y-%m-%d %H:%M:%S')
                        if sample.updated_at
                        else ''
                    )
            rows.append(row)

        if format_type == 'json':
            response = HttpResponse(
                json.dumps(rows, ensure_ascii=False, indent=2),
                content_type='application/json; charset=utf-8',
            )
            response['Content-Disposition'] = 'attachment; filename="samples_export.json"'
            return response

        if format_type in {'xlsx', 'excel'}:
            try:
                from openpyxl import Workbook
            except ImportError:
                return Response(
                    {'error': '–§–æ—Ä–º–∞—Ç Excel –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ openpyxl –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞)'},
                    status=status.HTTP_500_INTERNAL_SERVER_ERROR,
                )

            workbook = Workbook()
            sheet = workbook.active
            sheet.title = '–û–±—Ä–∞–∑—Ü—ã'
            if rows:
                headers = list(rows[0].keys())
                sheet.append(headers)
                for row in rows:
                    sheet.append(list(row.values()))

            output = BytesIO()
            workbook.save(output)
            output.seek(0)

            response = HttpResponse(
                output.getvalue(),
                content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            )
            response['Content-Disposition'] = 'attachment; filename="samples_export.xlsx"'
            return response

        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤–æ–∑–≤—Ä–∞—â–∞–µ–º CSV
        output = StringIO()
        writer = csv.writer(output)

        if rows:
            headers = list(rows[0].keys())
            writer.writerow(headers)
            for row in rows:
                writer.writerow(list(row.values()))

        response = HttpResponse(
            output.getvalue(),
            content_type='text/csv; charset=utf-8',
        )
        response['Content-Disposition'] = 'attachment; filename="samples_export.csv"'
        return response

    except Exception as exc:
        logger.error(f"Error in export_samples: {exc}")
        return Response(
            {'error': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –æ–±—Ä–∞–∑—Ü–æ–≤: {exc}'},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR,
        )


@extend_schema(
    summary='–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ–±—Ä–∞–∑—Ü–∞–º',
    responses={200: OpenApiResponse(description='–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –ø–æ –æ–±—Ä–∞–∑—Ü–∞–º')}
)
@api_view(['GET'])
def samples_stats(request):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –æ–±—Ä–∞–∑—Ü–∞–º."""

    try:
        total_count = Sample.objects.count()
        with_photo = Sample.objects.filter(has_photo=True).count()

        recent_days_raw = request.GET.get('recent_days', 30)
        try:
            recent_days = int(recent_days_raw)
        except (TypeError, ValueError):
            recent_days = 30
        recent_days = max(1, min(recent_days, 365))
        cutoff = timezone.now() - timedelta(days=recent_days)
        recent_additions = Sample.objects.filter(created_at__gte=cutoff).count()

        by_strain_qs = (
            Sample.objects.filter(strain__isnull=False)
            .values('strain__short_code')
            .annotate(count=Count('id'))
            .order_by('-count')[:10]
        )
        by_strain = {
            row['strain__short_code'] or '–ù–µ —É–∫–∞–∑–∞–Ω': row['count'] for row in by_strain_qs
        }

        by_iuk_color_qs = (
            Sample.objects.filter(iuk_color__isnull=False)
            .values('iuk_color__name')
            .annotate(count=Count('id'))
            .order_by('-count')[:10]
        )
        by_iuk_color = {
            row['iuk_color__name'] or '–ù–µ —É–∫–∞–∑–∞–Ω': row['count'] for row in by_iuk_color_qs
        }

        by_amylase_variant_qs = (
            Sample.objects.filter(amylase_variant__isnull=False)
            .values('amylase_variant__name')
            .annotate(count=Count('id'))
            .order_by('-count')[:10]
        )
        by_amylase_variant = {
            row['amylase_variant__name'] or '–ù–µ —É–∫–∞–∑–∞–Ω': row['count']
            for row in by_amylase_variant_qs
        }

        response_data = {
            'total': total_count,
            'with_photo': with_photo,
            'by_strain': by_strain,
            'by_iuk_color': by_iuk_color,
            'by_amylase_variant': by_amylase_variant,
            'recent_additions': recent_additions,
            'recent_days_window': recent_days,
        }

        return Response(response_data)

    except Exception as exc:
        logger.error(f"Error in samples_stats: {exc}")
        return Response(
            {'error': f'–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {exc}'},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR,
        )


@api_view(['POST'])
@csrf_exempt
def validate_sample(request):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–∞ –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è"""
    try:
        validated_data = CreateSampleSchema.model_validate(request.data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        validation_errors = []
        
        if validated_data.index_letter_id and not IndexLetter.objects.filter(id=validated_data.index_letter_id).exists():
            validation_errors.append({
                'type': 'value_error',
                'loc': ['index_letter_id'],
                'msg': f'–ò–Ω–¥–µ–∫—Å–Ω–∞—è –±—É–∫–≤–∞ —Å ID {validated_data.index_letter_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'
            })
        
        if validated_data.strain_id and not Strain.objects.filter(id=validated_data.strain_id).exists():
            validation_errors.append({
                'type': 'value_error',
                'loc': ['strain_id'],
                'msg': f'–®—Ç–∞–º–º —Å ID {validated_data.strain_id} –Ω–µ –Ω–∞–π–¥–µ–Ω'
            })
        
        if validated_data.storage_id and not Storage.objects.filter(id=validated_data.storage_id).exists():
            validation_errors.append({
                'type': 'value_error',
                'loc': ['storage_id'],
                'msg': f'–•—Ä–∞–Ω–∏–ª–∏—â–µ —Å ID {validated_data.storage_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'
            })
        
        if validated_data.source_id and not Source.objects.filter(id=validated_data.source_id).exists():
            validation_errors.append({
                'type': 'value_error',
                'loc': ['source_id'],
                'msg': f'–ò—Å—Ç–æ—á–Ω–∏–∫ —Å ID {validated_data.source_id} –Ω–µ –Ω–∞–π–¥–µ–Ω'
            })
        
        if validated_data.location_id and not Location.objects.filter(id=validated_data.location_id).exists():
            validation_errors.append({
                'type': 'value_error',
                'loc': ['location_id'],
                'msg': f'–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ —Å ID {validated_data.location_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'
            })
        
        if validated_data.iuk_color_id and not IUKColor.objects.filter(id=validated_data.iuk_color_id).exists():
            validation_errors.append({
                'type': 'value_error',
                'loc': ['iuk_color_id'],
                'msg': f'–¶–≤–µ—Ç –ò–£–ö —Å ID {validated_data.iuk_color_id} –Ω–µ –Ω–∞–π–¥–µ–Ω'
            })
        
        # –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: amylase_variant_id, appendix_note_id, comment_id –∏ growth_media_ids 
        # –Ω–µ —è–≤–ª—è—é—Ç—Å—è —á–∞—Å—Ç—å—é CreateSampleSchema, –ø–æ—ç—Ç–æ–º—É –∏—Ö –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ –Ω—É–∂–Ω–∞
        
        if validation_errors:
            return Response({
                'valid': False,
                'errors': validation_errors,
                'message': '–û—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö'
            })
        
        return Response({
            'valid': True,
            'data': validated_data.model_dump(),
            'errors': {},
            'message': '–î–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–∑—Ü–∞ –≤–∞–ª–∏–¥–Ω—ã'
        })
    except ValidationError as e:
        return Response({
            'valid': False,
            'errors': e.errors(),
            'message': '–û—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö'
        })
    except Exception as e:
        logger.error(f"Unexpected error in validate_sample: {e}")
        return Response({
            'valid': False,
            'errors': {'general': [str(e)]},
            'message': '–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞'
        })


# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
MAX_IMAGE_SIZE_MB = 1
ALLOWED_IMAGE_TYPES = ["image/jpeg", "image/png"]


def _validate_uploaded_image(uploaded_file):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–∞–µ–º–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    if uploaded_file.content_type not in ALLOWED_IMAGE_TYPES:
        raise DjangoValidationError("–†–∞–∑—Ä–µ—à–µ–Ω—ã —Ç–æ–ª—å–∫–æ JPEG –∏ PNG —Ñ–∞–π–ª—ã")

    if uploaded_file.size > MAX_IMAGE_SIZE_MB * 1024 * 1024:
        raise DjangoValidationError("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ 1 –ú–ë")


@extend_schema(
    summary="–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –æ–±—Ä–∞–∑—Ü–∞",
    description="–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–¥–Ω—É –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –¥–ª—è –æ–±—Ä–∞–∑—Ü–∞",
    responses={
        200: OpenApiResponse(description="–§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã"),
        400: OpenApiResponse(description="–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"),
        404: OpenApiResponse(description="–û–±—Ä–∞–∑–µ—Ü –Ω–µ –Ω–∞–π–¥–µ–Ω"),
    }
)
@api_view(["POST"])
@csrf_exempt
def upload_sample_photos(request, sample_id):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–¥–Ω—É –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –¥–ª—è –æ–±—Ä–∞–∑—Ü–∞."""
    try:
        sample = Sample.objects.get(id=sample_id)
    except Sample.DoesNotExist:
        return Response({"error": "–û–±—Ä–∞–∑–µ—Ü –Ω–µ –Ω–∞–π–¥–µ–Ω"}, status=status.HTTP_404_NOT_FOUND)

    if not request.FILES:
        return Response({"error": "–§–∞–π–ª—ã –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã"}, status=status.HTTP_400_BAD_REQUEST)

    created = []
    errors = []

    for file_obj in request.FILES.getlist("photos"):
        try:
            _validate_uploaded_image(file_obj)
            photo = sample.photos.create(image=file_obj)
            created.append({"id": photo.id, "url": photo.image.url})
        except DjangoValidationError as e:
            errors.append(str(e))
        except Exception as e:
            logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–æ—Ç–æ: %s", e)
            errors.append(str(e))

    # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–ª–∞–≥ has_photo –µ—Å–ª–∏ –±—ã–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
    if created:
        sample.has_photo = True
        sample.save(update_fields=['has_photo'])

    return Response({"created": created, "errors": errors})


@extend_schema(
    summary="–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –æ–±—Ä–∞–∑—Ü–∞",
    description="–£–¥–∞–ª—è–µ—Ç —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –æ–±—Ä–∞–∑—Ü–∞ –ø–æ ID",
    responses={
        200: OpenApiResponse(description="–§–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–∞"),
        404: OpenApiResponse(description="–§–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"),
    }
)
@api_view(["DELETE"])
@csrf_exempt
def delete_sample_photo(request, sample_id, photo_id):
    """–£–¥–∞–ª—è–µ—Ç —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –æ–±—Ä–∞–∑—Ü–∞."""
    try:
        photo = SamplePhoto.objects.get(id=photo_id, sample_id=sample_id)
        photo.delete()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Å—Ç–∞–ª–∏—Å—å –ª–∏ –µ—â–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —É –æ–±—Ä–∞–∑—Ü–∞
        sample = Sample.objects.get(id=sample_id)
        if not sample.photos.exists():
            sample.has_photo = False
            sample.save(update_fields=['has_photo'])
        
        return Response({"message": "–§–æ—Ç–æ —É–¥–∞–ª–µ–Ω–æ"})
    except SamplePhoto.DoesNotExist:
        return Response({"error": "–§–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"}, status=status.HTTP_404_NOT_FOUND)
    except Sample.DoesNotExist:
        return Response({"error": "–û–±—Ä–∞–∑–µ—Ü –Ω–µ –Ω–∞–π–¥–µ–Ω"}, status=status.HTTP_404_NOT_FOUND)


# Schemas for characteristics management
class CharacteristicOptionSchema(BaseModel):
    """–°—Ö–µ–º–∞ –¥–ª—è –æ–ø—Ü–∏–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫"""
    value: str = Field(min_length=1, max_length=200, description="–ó–Ω–∞—á–µ–Ω–∏–µ –æ–ø—Ü–∏–∏")
    display_name: str = Field(min_length=1, max_length=200, description="–û—Ç–æ–±—Ä–∞–∂–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ")
    color: Optional[str] = Field(None, max_length=20, description="–¶–≤–µ—Ç –æ–ø—Ü–∏–∏")


class CreateCharacteristicSchema(BaseModel):
    """–°—Ö–µ–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏"""
    name: str = Field(min_length=1, max_length=100, description="–ù–∞–∑–≤–∞–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏")
    display_name: str = Field(min_length=1, max_length=150, description="–û—Ç–æ–±—Ä–∞–∂–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ")
    characteristic_type: str = Field(description="–¢–∏–ø —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏")
    options: Optional[List[str]] = Field(None, description="–û–ø—Ü–∏–∏ –¥–ª—è select —Ç–∏–ø–∞")
    is_active: bool = Field(default=True, description="–ê–∫—Ç–∏–≤–Ω–∞ –ª–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞")
    order: int = Field(default=0, description="–ü–æ—Ä—è–¥–æ–∫ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")

    @field_validator('characteristic_type')
    @classmethod
    def validate_type(cls, v):
        if v not in ['boolean', 'text', 'select']:
            raise ValueError('–¢–∏–ø –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å boolean, text –∏–ª–∏ select')
        return v


# Characteristics management endpoints
@extend_schema(
    summary="–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫",
    description="–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –æ–±—Ä–∞–∑—Ü–æ–≤",
    responses={
        200: OpenApiResponse(description="–°–ø–∏—Å–æ–∫ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω"),
        500: OpenApiResponse(description="–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"),
    }
)
@api_view(['GET'])
@csrf_exempt
def list_characteristics(request):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫"""
    try:
        characteristics = SampleCharacteristic.objects.filter(is_active=True).order_by('display_name')
        
        result = []
        for char in characteristics:
            char_data = {
                'id': char.id,
                'name': char.name,
                'display_name': char.display_name,
                'characteristic_type': char.characteristic_type,
                'options': char.options or [],
                'is_active': char.is_active,
                'order': char.order
            }
            
            result.append(char_data)
        
        return Response(result)
    
    except Exception as e:
        logger.error(f"Error in list_characteristics: {e}")
        return Response({
            'error': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {str(e)}'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@extend_schema(
    summary="–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏",
    description="–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫—É –¥–ª—è –æ–±—Ä–∞–∑—Ü–æ–≤",
    request=CreateCharacteristicSchema,
    responses={
        200: OpenApiResponse(description="–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞"),
        400: OpenApiResponse(description="–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö"),
        500: OpenApiResponse(description="–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"),
    }
)
@api_view(['POST'])
@csrf_exempt
def create_characteristic(request):
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏"""
    try:
        data = CreateCharacteristicSchema(**request.data)
        
        with transaction.atomic():
            characteristic = SampleCharacteristic.objects.create(
                name=data.name,
                display_name=data.display_name,
                characteristic_type=data.characteristic_type,
                options=data.options,
                is_active=data.is_active,
                order=data.order
            )
            
            return Response({
                'id': characteristic.id,
                'message': f'–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ "{characteristic.display_name}" —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞'
            })
    
    except ValidationError as e:
        return Response({
            'error': '–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö',
            'details': e.errors()
        }, status=status.HTTP_400_BAD_REQUEST)
    
    except Exception as e:
        logger.error(f"Error in create_characteristic: {e}")
        return Response({
            'error': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {str(e)}'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@extend_schema(
    summary="–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏",
    description="–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫—É",
    request=CreateCharacteristicSchema,
    responses={
        200: OpenApiResponse(description="–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞"),
        400: OpenApiResponse(description="–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö"),
        404: OpenApiResponse(description="–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"),
        500: OpenApiResponse(description="–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"),
    }
)
@api_view(['PUT'])
@csrf_exempt
def update_characteristic(request, characteristic_id):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏"""
    try:
        characteristic = SampleCharacteristic.objects.get(id=characteristic_id)
    except SampleCharacteristic.DoesNotExist:
        return Response({
            'error': f'–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ —Å ID {characteristic_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'
        }, status=status.HTTP_404_NOT_FOUND)
    
    try:
        data = CreateCharacteristicSchema(**request.data)
        
        with transaction.atomic():
            characteristic.name = data.name
            characteristic.display_name = data.display_name
            characteristic.characteristic_type = data.characteristic_type
            characteristic.options = data.options
            characteristic.is_active = data.is_active
            characteristic.order = data.order
            characteristic.save()
            
            return Response({
                'id': characteristic.id,
                'message': f'–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ "{characteristic.display_name}" —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞'
            })
    
    except ValidationError as e:
        return Response({
            'error': '–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö',
            'details': e.errors()
        }, status=status.HTTP_400_BAD_REQUEST)
    
    except Exception as e:
        logger.error(f"Error in update_characteristic: {e}")
        return Response({
            'error': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {str(e)}'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@extend_schema(
    summary="–£–¥–∞–ª–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏",
    description="–£–¥–∞–ª—è–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫—É (–º—è–≥–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ)",
    responses={
        200: OpenApiResponse(description="–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–∞"),
        404: OpenApiResponse(description="–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"),
        500: OpenApiResponse(description="–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"),
    }
)
@api_view(['DELETE'])
@csrf_exempt
def delete_characteristic(request, characteristic_id):
    """–£–¥–∞–ª–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (–º—è–≥–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ)"""
    try:
        characteristic = SampleCharacteristic.objects.get(id=characteristic_id)
    except SampleCharacteristic.DoesNotExist:
        return Response({
            'error': f'–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ —Å ID {characteristic_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'
        }, status=status.HTTP_404_NOT_FOUND)
    
    try:
        with transaction.atomic():
            # –ú—è–≥–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ - –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ –Ω–µ–∞–∫—Ç–∏–≤–Ω—É—é
            characteristic.is_active = False
            characteristic.save()
            
            # –¢–∞–∫–∂–µ –¥–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –≤—Å–µ –æ–ø—Ü–∏–∏
            SampleCharacteristicOption.objects.filter(characteristic=characteristic).update(is_active=False)
            
            return Response({
                'message': f'–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ "{characteristic.display_name}" —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–∞'
            })
    
    except Exception as e:
        logger.error(f"Error in delete_characteristic: {e}")
        return Response({
            'error': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {str(e)}'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
