#!/usr/bin/env python
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV —Ñ–∞–π–ª–æ–≤ –≤ PostgreSQL –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
—á–µ—Ä–µ–∑ –º–æ–¥–µ–ª–∏ Django —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π Pydantic
"""

import os
import sys
from pathlib import Path

import django
import pandas as pd
from django.conf import settings
from django.db import transaction
from pydantic import ValidationError

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ (/app) –≤ PYTHONPATH, —á—Ç–æ–±—ã Django –Ω–∞—à–µ–ª –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
project_root = Path(__file__).resolve().parent.parent.parent
sys.path.append(str(project_root / "backend"))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Django
os.environ.setdefault(
    "DJANGO_SETTINGS_MODULE", "strain_tracker_project.settings"
)
django.setup()

from collection_manager.models import (AppendixNote, Comment,  # noqa: E402
                                       IndexLetter, Location, Sample, Source,
                                       Storage, Strain)
from collection_manager.schemas import (ImportAppendixNoteSchema,  # noqa: E402
                                        ImportCommentSchema,
                                        ImportIndexLetterSchema,
                                        ImportLocationSchema,
                                        ImportSampleSchema, ImportSourceSchema,
                                        ImportStorageSchema,
                                        ImportStrainSchema,
                                        validate_boolean_from_csv,
                                        validate_csv_row)


@transaction.atomic
def str_to_bool(value):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å—Ç—Ä–æ–∫–∏ –≤ –±—É–ª–µ–≤–æ –∑–Ω–∞—á–µ–Ω–∏–µ"""
    if pd.isna(value) or value == "":
        return False
    return str(value).lower() in ["true", "1", "yes", "–¥–∞", "+"]


@transaction.atomic
def import_index_letters():
    """–ò–º–ø–æ—Ä—Ç –∏–Ω–¥–µ–∫—Å–Ω—ã—Ö –±—É–∫–≤ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    print("üìù –ò–º–ø–æ—Ä—Ç –∏–Ω–¥–µ–∫—Å–Ω—ã—Ö –±—É–∫–≤...")
    df = pd.read_csv(project_root / "data" / "IndexLetters_Table.csv")

    validated_count = 0
    for index, row in df.iterrows():
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            validated_data = validate_csv_row(
                ImportIndexLetterSchema,
                row.to_dict(),
                row_number=index
                + 2,  # +2 –¥–ª—è —É—á–µ—Ç–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Å 1
            )

            IndexLetter.objects.get_or_create(
                id=validated_data.IndexLetterID,
                defaults={"letter_value": validated_data.IndexLetterValue},
            )
            validated_count += 1

        except (ValidationError, ValueError) as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–æ–∫–µ {index + 2}: {e}")
            continue

    print(f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {validated_count} –∏–∑ {len(df)} –∏–Ω–¥–µ–∫—Å–Ω—ã—Ö –±—É–∫–≤")


@transaction.atomic
def import_locations():
    """–ò–º–ø–æ—Ä—Ç –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–π —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    print("üåç –ò–º–ø–æ—Ä—Ç –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–π...")
    df = pd.read_csv(project_root / "data" / "Locations_Table.csv")

    validated_count = 0
    for index, row in df.iterrows():
        try:
            validated_data = validate_csv_row(
                ImportLocationSchema, row.to_dict(), row_number=index + 2
            )

            Location.objects.get_or_create(
                id=validated_data.LocationID,
                defaults={"name": validated_data.LocationNameValue},
            )
            validated_count += 1

        except (ValidationError, ValueError) as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–æ–∫–µ {index + 2}: {e}")
            continue

    print(f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {validated_count} –∏–∑ {len(df)} –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–π")


@transaction.atomic
def import_sources():
    """–ò–º–ø–æ—Ä—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    print("üî¨ –ò–º–ø–æ—Ä—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")
    df = pd.read_csv(project_root / "data" / "Sources_Table.csv")

    validated_count = 0
    for index, row in df.iterrows():
        try:
            validated_data = validate_csv_row(
                ImportSourceSchema, row.to_dict(), row_number=index + 2
            )

            Source.objects.get_or_create(
                id=validated_data.SourceID,
                defaults={
                    "organism_name": validated_data.SourceOrganismName,
                    "source_type": validated_data.SourceTypeName,
                    "category": validated_data.SourceCategoryName,
                },
            )
            validated_count += 1

        except (ValidationError, ValueError) as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–æ–∫–µ {index + 2}: {e}")
            continue

    print(f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {validated_count} –∏–∑ {len(df)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")


@transaction.atomic
def import_comments():
    """–ò–º–ø–æ—Ä—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    print("üí¨ –ò–º–ø–æ—Ä—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤...")
    df = pd.read_csv(project_root / "data" / "Comments_Table.csv")

    validated_count = 0
    for index, row in df.iterrows():
        try:
            validated_data = validate_csv_row(
                ImportCommentSchema, row.to_dict(), row_number=index + 2
            )

            Comment.objects.get_or_create(
                id=validated_data.CommentID,
                defaults={"text": validated_data.CommentTextValue},
            )
            validated_count += 1

        except (ValidationError, ValueError) as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–æ–∫–µ {index + 2}: {e}")
            continue

    print(f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {validated_count} –∏–∑ {len(df)} –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤")


@transaction.atomic
def import_appendix_notes():
    """–ò–º–ø–æ—Ä—Ç –ø—Ä–∏–º–µ—á–∞–Ω–∏–π —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    print("üìã –ò–º–ø–æ—Ä—Ç –ø—Ä–∏–º–µ—á–∞–Ω–∏–π...")
    df = pd.read_csv(project_root / "data" / "AppendixNotes_Table.csv")

    validated_count = 0
    for index, row in df.iterrows():
        try:
            validated_data = validate_csv_row(
                ImportAppendixNoteSchema, row.to_dict(), row_number=index + 2
            )

            AppendixNote.objects.get_or_create(
                id=validated_data.AppendixNoteID,
                defaults={"text": validated_data.AppendixNoteText},
            )
            validated_count += 1

        except (ValidationError, ValueError) as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–æ–∫–µ {index + 2}: {e}")
            continue

    print(f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {validated_count} –∏–∑ {len(df)} –ø—Ä–∏–º–µ—á–∞–Ω–∏–π")


@transaction.atomic
def import_storage_data():
    file_path = os.path.join(
        settings.BASE_DIR, "..", "data", "Storage_Table.csv"
    )
    try:
        # –£–∫–∞–∑—ã–≤–∞–µ–º dtype=str, —á—Ç–æ–±—ã pandas —á–∏—Ç–∞–ª –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏ –∏ –Ω–µ –±—ã–ª–æ –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        df = pd.read_csv(file_path, sep=",", header=0, dtype=str)
        df = df.where(pd.notna(df), None)

        print("üì¶ –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Ö—Ä–∞–Ω–µ–Ω–∏–∏...")

        storage_objects = []
        validated_count = 0
        error_count = 0

        for index, row in df.iterrows():
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º .model_dump() –≤–º–µ—Å—Ç–æ .dict() –¥–ª—è Pydantic v2
                storage_data = ImportStorageSchema.model_validate(
                    row.to_dict()
                )
                # –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –º–∞–ø–ø–∏–Ω–≥ –ø–æ–ª–µ–π –∏–∑ —Å—Ö–µ–º—ã –≤ –º–æ–¥–µ–ª—å
                storage_objects.append(Storage(
                    box_id=storage_data.BoxIDValue,
                    cell_id=storage_data.CellIDValue
                ))
                validated_count += 1
            except ValidationError as e:
                print(f"  [!] –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è —Å—Ç—Ä–æ–∫–∏ {index + 2}: {e}")
                error_count += 1

        if error_count == 0:
            Storage.objects.bulk_create(storage_objects, batch_size=500)
            print(
                f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {validated_count} –∏–∑ {len(df)} –∑–∞–ø–∏—Å–µ–π –æ —Ö—Ä–∞–Ω–µ–Ω–∏–∏"
            )
        else:
            print(
                f"‚ùå –ò–º–ø–æ—Ä—Ç —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç–º–µ–Ω–µ–Ω –∏–∑-–∑–∞ {error_count} –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏."
            )

    except FileNotFoundError:
        print(f"  [!] –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
    except Exception as e:
        print(f"  [!] –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ —Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")


@transaction.atomic
def import_strains():
    """–ò–º–ø–æ—Ä—Ç —à—Ç–∞–º–º–æ–≤ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    print("ü¶† –ò–º–ø–æ—Ä—Ç —à—Ç–∞–º–º–æ–≤...")
    df = pd.read_csv(project_root / "data" / "Strains_Table.csv")

    validated_count = 0
    for index, row in df.iterrows():
        try:
            # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            row_dict = row.to_dict()
            for key, value in row_dict.items():
                if pd.isna(value) or value == "":
                    row_dict[key] = None

            validated_data = validate_csv_row(
                ImportStrainSchema, row_dict, row_number=index + 2
            )

            Strain.objects.get_or_create(
                id=validated_data.StrainID,
                defaults={
                    "short_code": validated_data.ShortStrainCode,
                    "rrna_taxonomy": validated_data.RRNATaxonomy,
                    "identifier": validated_data.StrainIdentifierValue,
                    "name_alt": validated_data.StrainNameAlt,
                    "rcam_collection_id": validated_data.RCAMCollectionID,
                },
            )
            validated_count += 1

        except (ValidationError, ValueError) as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–æ–∫–µ {index + 2}: {e}")
            continue

    print(f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {validated_count} –∏–∑ {len(df)} —à—Ç–∞–º–º–æ–≤")


@transaction.atomic
def import_samples():
    """–ò–º–ø–æ—Ä—Ç –æ–±—Ä–∞–∑—Ü–æ–≤ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    print("üß™ –ò–º–ø–æ—Ä—Ç –æ–±—Ä–∞–∑—Ü–æ–≤...")
    df = pd.read_csv(project_root / "data" / "Samples_Table.csv")

    validated_count = 0
    for index, row in df.iterrows():
        try:
            # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            row_dict = row.to_dict()
            for key, value in row_dict.items():
                if pd.isna(value) or value == "":
                    row_dict[key] = (
                        None
                        if "_FK" in key or key == "OriginalSampleNumber"
                        else ""
                    )
                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –±—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                elif (
                    key.startswith("Has")
                    or key == "IsIdentified"
                    or key == "SEQStatus"
                ):
                    row_dict[key] = str(value).lower()

            validated_data = validate_csv_row(
                ImportSampleSchema, row_dict, row_number=index + 2
            )

            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ (–º–æ–∂–µ—Ç –±—ã—Ç—å None –¥–ª—è –ø—É—Å—Ç—ã—Ö —è—á–µ–µ–∫)
            def get_foreign_object(model_class, field_id):
                if field_id is None:
                    return None
                try:
                    return model_class.objects.get(id=field_id)
                except model_class.DoesNotExist:
                    print(
                        f"‚ö†Ô∏è  {model_class.__name__} —Å ID {field_id} –Ω–µ –Ω–∞–π–¥–µ–Ω"
                    )
                    return None

            index_letter = get_foreign_object(
                IndexLetter, validated_data.IndexLetterID_FK
            )
            strain = get_foreign_object(Strain, validated_data.StrainID_FK)
            storage = get_foreign_object(Storage, validated_data.StorageID_FK)
            source = get_foreign_object(Source, validated_data.SourceID_FK)
            location = get_foreign_object(
                Location, validated_data.LocationID_FK
            )
            appendix_note_obj = get_foreign_object(
                AppendixNote, validated_data.AppendixNoteID_FK
            )
            comment_obj = get_foreign_object(Comment, validated_data.CommentID_FK)
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –æ–±—ä–µ–∫—Ç–æ–≤
            appendix_note_text = appendix_note_obj.text if appendix_note_obj else None
            comment_text = comment_obj.text if comment_obj else None

            Sample.objects.update_or_create(
                id=validated_data.SampleRowID,
                defaults={
                    "index_letter": index_letter,
                    "strain": strain,
                    "storage": storage,
                    "original_sample_number": validated_data.OriginalSampleNumber,
                    "source": source,
                    "location": location,
                    "appendix_note": appendix_note_text,
                    "comment": comment_text,
                    "has_photo": validate_boolean_from_csv(
                        validated_data.HasPhoto
                    ),
                    "is_identified": validate_boolean_from_csv(
                        validated_data.IsIdentified
                    ),
                    "has_antibiotic_activity": validate_boolean_from_csv(
                        validated_data.HasAntibioticActivity
                    ),
                    "has_genome": validate_boolean_from_csv(
                        validated_data.HasGenome
                    ),
                    "has_biochemistry": validate_boolean_from_csv(
                        validated_data.HasBiochemistry
                    ),
                    "seq_status": validate_boolean_from_csv(
                        validated_data.SEQStatus
                    ),
                },
            )
            validated_count += 1

        except (ValidationError, ValueError) as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–æ–∫–µ {index + 2}: {e}")
            continue

    print(f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {validated_count} –∏–∑ {len(df)} –æ–±—Ä–∞–∑—Ü–æ–≤")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–º–ø–æ—Ä—Ç–∞"""
    print("==================================================")
    print("üöÄ –ó–∞–ø—É—Å–∫ –∏–º–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É...")

    import_index_letters()
    import_locations()
    import_sources()
    import_comments()
    import_appendix_notes()
    import_storage_data()
    import_strains()
    import_samples()

    print("==================================================")
    print("üéâ –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
    print("")


if __name__ == "__main__":
    main()
